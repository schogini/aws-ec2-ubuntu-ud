Labels
Having already learned about Pods and how to create them, you may be struck by an urge to create many, many Pods. Please do! But eventually you will need a system to organize these Pods into groups. The system for achieving this in Kubernetes is Labels. Labels are key-value pairs that are attached to each object in Kubernetes. Label selectors can be passed along with a RESTful list request to the apiserver to retrieve a list of objects which match that label selector.

To add a label, add a labels section under metadata in the Pod definition:

  labels:
    env: test


kubectl create -f https://k8s.io/examples/pods/pod-nginx.yaml


Deployments
Now that you know how to make awesome, multi-container, labeled Pods and you want to use them to build an application, you might be tempted to just start building a whole bunch of individual Pods, but if you do that, a whole host of operational concerns pop up. For example: how will you scale the number of Pods up or down? How will you roll out a new release?

The answer to those questions and more is to use a Deployment to manage maintaining and updating your running Pods.

A Deployment object defines a Pod creation template (a “cookie-cutter” if you will) and desired replica count. The Deployment uses a label selector to identify the Pods it manages, and will create or delete Pods as needed to meet the replica count. Deployments are also used to manage safely rolling out changes to your running Pods

SreeMacMin16GB:k-201 sree$ cat deployment-2nginx.yaml 
apiVersion: apps/v1 # for versions before 1.9.0 use apps/v1beta2
kind: Deployment
metadata:
  name: nginx-deployment
spec:
  selector:
    matchLabels:
      app: nginx
  replicas: 2 # tells deployment to run 2 pods matching the template
  template:
    metadata:
      labels:
        app: nginx
    spec:
      containers:
      - name: nginx
        image: nginx:1.7.9
        ports:
        - containerPort: 80
SreeMacMin16GB:k-201 sree$ kubectl create -f deployment-2nginx.yaml 
deployment.apps/nginx-deployment created
SreeMacMin16GB:k-201 sree$ kubectl get deployment
NAME               DESIRED   CURRENT   UP-TO-DATE   AVAILABLE   AGE
nginx-deployment   2         2         2            2           20s
nginx-sree         1         1         1            1           1d
SreeMacMin16GB:k-201 sree$ kubectl get pods -l app=nginx
NAME                                READY     STATUS    RESTARTS   AGE
nginx-deployment-75675f5897-mz4jg   1/1       Running   0          35s
nginx-deployment-75675f5897-ql7n9   1/1       Running   0          35s
SreeMacMin16GB:k-201 sree$ 


APPLY

SreeMacMin16GB:k-201 sree$ cat deployment-2nginx.yaml 
apiVersion: apps/v1 # for versions before 1.9.0 use apps/v1beta2
kind: Deployment
metadata:
  name: nginx-deployment
spec:
  selector:
    matchLabels:
      app: nginx
  replicas: 2 # tells deployment to run 2 pods matching the template
  template:
    metadata:
      labels:
        app: nginx
    spec:
      containers:
      - name: nginx
        image: nginx:1.8
        ports:
        - containerPort: 80
SreeMacMin16GB:k-201 sree$ kubectl apply -f deployment-2nginx.yaml 
Warning: kubectl apply should be used on resource created by either kubectl create --save-config or kubectl apply
deployment.apps/nginx-deployment configured
SreeMacMin16GB:k-201 sree$ kubectl get pods -l app=nginx
NAME                                READY     STATUS    RESTARTS   AGE
nginx-deployment-6ddf4c5bf7-pg5xf   1/1       Running   0          23s
nginx-deployment-6ddf4c5bf7-x4xwl   1/1       Running   0          21s
SreeMacMin16GB:k-201 sree$ 

kubectl delete deployment nginx-deployment



Services
Once you have a replicated set of Pods, you need an abstraction that enables connectivity between the layers of your application. For example, if you have a Deployment managing your backend jobs, you don’t want to have to reconfigure your front-ends whenever you re-scale your backends. Likewise, if the Pods in your backends are scheduled (or rescheduled) onto different machines, you can’t be required to re-configure your front-ends. In Kubernetes, the service abstraction achieves these goals. A service provides a way to refer to a set of Pods (selected by labels) with a single static IP address. It may also provide load balancing, if supported by the provider.


SreeMacMin16GB:k-201 sree$ cat service-nginx.yaml
apiVersion: v1
kind: Service
metadata:
  name: nginx-service
spec:
  ports:
  - port: 8000 # the port that this service should serve on
    # the container on each pod to connect to, can be a name
    # (e.g. 'www') or a number (e.g. 80)
    targetPort: 80
    protocol: TCP
  # just like the selector in the deployment,
  # but this time it identifies the set of pods to load balance
  # traffic to.
  selector:
    app: nginx
SreeMacMin16GB:k-201 sree$ kubectl create -f service-nginx.yaml 
service/nginx-service created
SreeMacMin16GB:k-201 sree$ kubectl get services
NAME            TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)    AGE
kubernetes      ClusterIP   10.96.0.1       <none>        443/TCP    39d
nginx-service   ClusterIP   10.104.218.22   <none>        8000/TCP   11s


SreeMacMin16GB:k-201 sree$ kubectl get service nginx-service
NAME            TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)    AGE
nginx-service   ClusterIP   10.104.218.22   <none>        8000/TCP   2m
SreeMacMin16GB:k-201 sree$ kubectl get service nginx-service -o go-template='{{.spec.clusterIP}}'
10.104.218.22

export SERVICE_IP=$(kubectl get service nginx-service -o go-template='{{.spec.clusterIP}}')
export SERVICE_PORT=$(kubectl get service nginx-service -o go-template='{{(index .spec.ports 0).port}}')
echo "$SERVICE_IP:$SERVICE_PORT"
10.104.218.22:8000

kubectl run busybox  --generator=run-pod/v1 --image=busybox --restart=Never --tty -i --env "SERVICE_IP=$SERVICE_IP" --env "SERVICE_PORT=$SERVICE_PORT"

SreeMacMin16GB:k-201 sree$ export SERVICE_IP=$(kubectl get service nginx-service -o go-template='{{.spec.clusterIP}}')
SreeMacMin16GB:k-201 sree$ export SERVICE_PORT=$(kubectl get service nginx-service -o go-template='{{(index .spec.ports 0).port}}')
SreeMacMin16GB:k-201 sree$ echo "$SERVICE_IP:$SERVICE_PORT"
10.108.79.180:8000
SreeMacMin16GB:k-201 sree$ kubectl run busybox  --generator=run-pod/v1 --image=busybox --restart=Never --tty -i --env "SERVICE_IP=$SERVICE_IP" --env "SERVICE_PORT=$SERVICE_PORT"
Error from server (AlreadyExists): pods "busybox" already exists
SreeMacMin16GB:k-201 sree$ kubectl delete pod busybox
pod "busybox" deleted
SreeMacMin16GB:k-201 sree$ kubectl run busybox  --generator=run-pod/v1 --image=busybox --restart=Never --tty -i --env "SERVICE_IP=$SERVICE_IP" --env "SERVICE_PORT=$SERVICE_PORT"
If you don't see a command prompt, try pressing enter.
/ # 

/ # wget -qO- http://$SERVICE_IP:$SERVICE_PORT
<!DOCTYPE html>
<html>
<head>
<title>Welcome to nginx!</title>

/ # exit
SreeMacMin16GB:k-201 sree$ kubectl delete pod busybox
pod "busybox" deleted
SreeMacMin16GB:k-201 sree$ kubectl delete service nginx-service
service "nginx-service" deleted



Health Checking
When I write code it never crashes, right? Sadly the Kubernetes issues list indicates otherwise…

Rather than trying to write bug-free code, a better approach is to use a management system to perform periodic health checking and repair of your application. That way a system outside of your application itself is responsible for monitoring the application and taking action to fix it. It’s important that the system be outside of the application, since if your application fails and the health checking agent is part of your application, it may fail as well and you’ll never know. In Kubernetes, the health check monitor is the Kubelet agent.


Process Health Checking
The simplest form of health-checking is just process level health checking. The Kubelet constantly asks the Docker daemon if the container process is still running, and if not, the container process is restarted. In all of the Kubernetes examples you have run so far, this health checking was actually already enabled. It’s on for every single container that runs in Kubernetes.


Application Health Checking
However, in many cases this low-level health checking is insufficient. From Docker’s perspective your application could be still running, but from your application’s perspective your code could be locked up.

To address this problem, Kubernetes supports user implemented application health-checks. These checks are performed by the Kubelet to ensure that your application is operating correctly for a definition of “correctly” that you provide.

Currently, there are three types of application health checks that you can choose from:

HTTP Health Checks - The Kubelet will call a web hook. If it returns between 200 and 399, it is considered success, failure otherwise. See health check examples here.
Container Exec - The Kubelet will execute a command inside your container. If it exits with status 0 it will be considered a success. See health check examples here.
TCP Socket - The Kubelet will attempt to open a socket to your container. If it can establish a connection, the container is considered healthy, if it can’t it is considered a failure.
In all cases, if the Kubelet discovers a failure the container is restarted.










